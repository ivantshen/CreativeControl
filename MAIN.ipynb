{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a0b91f-1ab1-423d-890d-3c0f4e3c6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir('Lib/site-packages')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "import ffmpeg\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import uuid\n",
    "#import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from lumaai import LumaAI\n",
    "from typing import Literal, TypedDict\n",
    "from elevenlabs.client import ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7c9450-b7f9-49e2-846a-03b8bead1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUMA\n",
    "client = LumaAI(\n",
    "    auth_token=os.environ.get(\"LUMAAI_API_KEY\"),\n",
    ")\n",
    "#OPENAI\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "#ELEVENLABS\n",
    "elevenlabs_client = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "#LANGCHAIN llms\n",
    "supervisor_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "video_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "storyboard_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "audio_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "#editor_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "generatingVid = False\n",
    "fullDialogueString = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dc3f3-a4e8-4fd0-9ffc-b7244c81da71",
   "metadata": {},
   "source": [
    "## TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bd710-06c9-432d-9602-c38a3f7a5fba",
   "metadata": {},
   "source": [
    "### Video Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9958d677-52aa-48e2-a95b-5e2278d3254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMAS\n",
    "class video_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a video using text input and returns a filepath to the video\"\"\"\n",
    "    vid_prompt: str = Field(..., description=\"The textual prompt used in generating the video\")\n",
    "    use_9s: bool = Field(..., description=\"Whether to generate a 9 second long video. If set to FALSE, this will generate a 5 second long video\")\n",
    "\n",
    "\n",
    "@tool(\"video_gen_tool\",args_schema=video_gen_schema)   \n",
    "def generate_vid(vid_prompt: str, use_9s: bool) -> str:\n",
    "    global generatingVid\n",
    "    if(generatingVid):\n",
    "        return \"Failed to generate video, there is currently another video being generated.\"\n",
    "    dur = \"5s\"\n",
    "    if(use_9s):\n",
    "        dur = \"9s\"\n",
    "    print(f\"VIDEOWORKER PROMPT: {dur}\\n------------------------------\\n\" + vid_prompt)\n",
    "    generatingVid = True\n",
    "    generation = client.generations.create(\n",
    "        prompt=vid_prompt,\n",
    "        model=\"ray-2\",\n",
    "        resolution=\"720p\",\n",
    "        duration=dur\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating vid\")\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(5)\n",
    "    video_url = generation.assets.video\n",
    "    # download the video\n",
    "    response = requests.get(video_url, stream=True)\n",
    "    with open(f'staticVid1/{generation.id}.mp4', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Video generated in staticVid1/{generation.id}.mp4\")\n",
    "    generatingVid = False\n",
    "    return f\"Video generated in staticVid1/{generation.id}.mp4\"\n",
    "\n",
    "#class extend_video_schema(BaseModel):\n",
    "video_tools = [generate_vid]\n",
    "video_tool_node = ToolNode(video_tools)\n",
    "video_worker = video_gen_llm.bind_tools(video_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5b6e-939f-4b35-b636-9e8842e04e44",
   "metadata": {},
   "source": [
    "### Storyboard Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91838bf-2756-46e3-955b-8689016710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMA\n",
    "class step_by_step_output_schema(BaseModel):\n",
    "    \"\"\"Prints a storyboard for the user to view in string format\"\"\"\n",
    "    story_description: str = Field(..., description=\"A 200-250 word description of the story\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of each character in the scene\")\n",
    "    background_details: str = Field(..., description=\"A 50-100 description of the scene\")\n",
    "    auditory_details: str = Field(..., description=\"A 50-100 description of the voice profile of each character\")\n",
    "    dialogue_details: str = Field(..., description=\"The parts of the dialogue that require enunciation and emotion\")\n",
    "    num_characters: int = Field(..., description=\"The number of unique characters present in this scene\")\n",
    "    pure_dialogue: str = Field(..., description=\"The extracted dialogue from the input scene with character name appended before. Within the dialogue, indicate dialogue details that require enunciation and emotion with descriptors in parentheses Format: {CharacterName}: {Dialogue (Enunciation) Dialogue Detail}\")\n",
    "\n",
    "charProfileQueue = 0\n",
    "@tool(\"storyboard_tool\",args_schema=step_by_step_output_schema)\n",
    "def generate_storyboard(story_description: str,character_details: str,background_details: str,auditory_details: str,dialogue_details: str, num_characters: int,pure_dialogue: str) -> str:\n",
    "    global fullDialogueString\n",
    "    global charProfileQueue\n",
    "    print(\"storyboarding\")\n",
    "    temp_storyboard = \"STORY ANALYSIS\\n------------------------------\\n\"+story_description+\"\\nCHARACTERS\\n------------------------------\\n\"+character_details\n",
    "    temp_storyboard+=\"\\nBACKGROUND\\n------------------------------\\n\"+background_details+\"\\nAUDIO\\n------------------------------\\n\"+auditory_details+\"\\nDIALOGUE\\n------------------------------\\n\"\n",
    "    temp_storyboard+=dialogue_details+\"\\nNumber of characters\\n------------------------------\\n\"+ str(num_characters)+\"\\nPure Dialogue\\n------------------------------\\n\" + pure_dialogue\n",
    "    print(temp_storyboard)\n",
    "    fullDialogueString = pure_dialogue\n",
    "    charProfileQueue = num_characters\n",
    "    return temp_storyboard\n",
    "\n",
    "class character_profile_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a character profile for a character and returns the filepath\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character, taken from the script\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of the character in the scene, taken from the script\")\n",
    "\n",
    "@tool(\"character_profile_tool\",args_schema=character_profile_gen_schema)\n",
    "def generate_character_profile(character_name: str, character_details: str)->str:\n",
    "    global charProfileQueue\n",
    "    if(charProfileQueue<=0):\n",
    "        return \"Already generated character profiles!\"\n",
    "    generation = client.generations.image.create(\n",
    "      prompt=\"Generate a hyperrealistic, front-facing portrait \\\n",
    "      The image should feature perfectly even, diffused lighting that completely\\\n",
    "      eliminates any shadows on the face. Use a direct, center-camera angle against a neutral,\\\n",
    "      unobtrusive background to ensure absolute consistency. Focus on lifelike details with natural \\\n",
    "      skin textures and realistic, balanced color tones, making the portrait suitable as a reference\\\n",
    "      for video character consistency.: \"+character_name+\", \"+character_details,\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating char profile for: \" + character_name)\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(2)\n",
    "    image_url = generation.assets.image\n",
    "    print(\"image_url: \" +image_url)\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    with open(f'charRef/{generation.id}.jpg', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Image generated in charRef/{generation.id}.jpg\")\n",
    "    charProfileQueue-=1;\n",
    "    return f\"Image generated in charRef/{generation.id}.jpg\"\n",
    "\n",
    "storyboard_tools = [generate_storyboard,generate_character_profile]\n",
    "storyboard_tool_node = ToolNode(storyboard_tools)\n",
    "storyboard_worker = storyboard_llm.bind_tools(storyboard_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf12443-0259-452e-bf07-27d0d57f9593",
   "metadata": {},
   "source": [
    "### Audio Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd454937-f86f-4a39-84fa-e8671ce437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dialogue_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a dialogue mp3 clip and returns the filepath to the audio\"\"\"\n",
    "    dialogue_text: str = Field(..., description=\"The dialogue text of a SINGLE character for a particular scene.\")\n",
    "    voice_idx: int = Field(..., description=\"Out of the following voice ids, choose the index of the one that best suits the character who is speaking:\\\n",
    "    [{29vD33N1CtxCmqQRPOHJ: Male young and nervous},{N2lVS1w4EtoT3dr4eOWO: Male booming and imposing},\\\n",
    "    {21m00Tcm4TlvDq8ikWAM: Female elegant and slightly teasing}]\")\n",
    "\n",
    "@tool(\"dialogue_gen_tool\",args_schema=dialogue_gen_schema)\n",
    "def generate_dialogue(dialogue_text: str, voice_idx: int) -> str:\n",
    "    print(\"attempted dialogue: \" +dialogue_text+\"\\nattempted idx: \" + str(voice_idx))\n",
    "    voice_ids = [\"29vD33N1CtxCmqQRPOHJ\",\"N2lVS1w4EtoT3dr4eOWO\",\"21m00Tcm4TlvDq8ikWAM\"]\n",
    "    eleven_response = elevenlabs_client.text_to_speech.convert(\n",
    "        voice_id=voice_ids[voice_idx],\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_44100_128\",\n",
    "        text=dialogue_text,\n",
    "        model_id=\"eleven_turbo_v2\",\n",
    "    )\n",
    "\n",
    "    # Save the file into the raw_audio directory\n",
    "    raw_audio_dir = \"staticAudio1\"\n",
    "    os.makedirs(raw_audio_dir, exist_ok=True)\n",
    "    file_path = os.path.join(raw_audio_dir, f\"{uuid.uuid4()}.mp3\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        for chunk in eleven_response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return file_path\n",
    "\n",
    "audio_tools = [generate_dialogue]\n",
    "audio_tool_node = ToolNode(audio_tools)\n",
    "audio_worker = audio_gen_llm.bind_tools(audio_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a750a2f-6132-407a-b409-57ce8329ca93",
   "metadata": {},
   "source": [
    "### Editor Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76812a2d-d0f4-4679-91e2-ed9e49ede09d",
   "metadata": {},
   "source": [
    "## RUNNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbeb42-ff84-4b08-89ac-e84f2471fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor\n",
      "traveling\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "storyboarding\n",
      "STORY ANALYSIS\n",
      "------------------------------\n",
      "In the modern day, Montague Museum, a former grand family home now turned into a museum akin to Hearst Castle, Elizabeth Montague engages in a heated argument with Ethan. Elizabeth, the fiercely intense and angry descendant of the Montague family, confronts Ethan about a secret concerning the family's history that must remain hidden. Ethan, however, is adamant that he will reveal the truth, opposing Elizabeth's stance and highlighting the internal conflict between preserving legacy and honesty.\n",
      "CHARACTERS\n",
      "------------------------------\n",
      "Elizabeth Montague is a strong-willed, passionate woman with a deep-seated sense of responsibility towards her family's legacy. She often finds herself at odds between personal ethics and familial duties, portraying an intense demeanor, especially when confronted with threats to her family's secrets. Her expressions are sharp, and her speech carries an authoritative undertone, reflecting her resolute nature and the weight of her ancestral lineage. Ethan, on the other hand, is a spirited individual, driven by a moral compass that steers him towards transparency and honesty. He is not easily intimidated by Elizabeth's authoritative presence, and his posture and facial expressions convey a mix of defiance and righteousness. He believes in the power of truth and is willing to stand his ground against Elizabeth's demands for secrecy.\n",
      "BACKGROUND\n",
      "------------------------------\n",
      "The Montague Museum, once a grand family home, now resembles a Hearst Castle-like museum. It features opulent architecture with elegant interiors, high ceilings, and a rich history encapsulated within its walls. The room where the argument takes place is filled with relics and artifacts showcasing the Montague legacy, adding a layer of tension and history to the scene.\n",
      "AUDIO\n",
      "------------------------------\n",
      "Elizabeth's voice is commanding and sharp, often tinged with impatience and anger. Her words are clipped, yet filled with an undeniable sense of urgency and desperation. Ethan's voice, in contrast, is steady and firm. There's a resolve in his tone that reflects his unwavering commitment to revealing the truth, even when faced with Elizabeth's domineering personality.\n",
      "DIALOGUE\n",
      "------------------------------\n",
      "Elizabeth's dialogue requires enunciation with a tone of authority and anger. Her lines should convey a sense of urgency and command as she tries to contain the situation. Ethan's responses demand clarity and conviction, focusing on his determination to unveil the truth. The emotional undertone between them adds a palpable intensity to the dialogue.\n",
      "Number of characters\n",
      "------------------------------\n",
      "2\n",
      "Pure Dialogue\n",
      "------------------------------\n",
      "Elizabeth: You know you can’t tell a soul, right? (Enunciation: Authority, Anger) Ethan: Are you kidding? I’m going to tell everyone. You can’t hide this. (Enunciation: Clarity, Conviction)\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "generating char profile for: Elizabeth Montague\n",
      "generating char profile for: Ethan\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:completed\n",
      "Dreaming, state:dreaming\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/2681c081-8ea4-4c8c-ae36-1be098fa1b2c/d5eeab51-582f-4b46-ad10-853e6c34e61f_result.jpg\n",
      "Image generated in charRef/2a5381d1-7f8d-472a-b798-24827d590f6d.jpg\n",
      "Dreaming, state:completed\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/9e1b531c-f999-4e71-a2e4-970b6dddf9ec/931aaee2-14ab-4df4-82b6-6e9e95e095bb_result.jpg\n",
      "Image generated in charRef/25e3be0c-9ce3-4767-8922-7f6f1f08c02f.jpg\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "supervisor\n",
      "traveling\n",
      "audio worker\n",
      "check audio tool call\n",
      "attempted dialogue: Elizabeth: You know you can’t tell a soul, right? (Enunciation: Authority, Anger)\n",
      "attempted idx: 2\n",
      "attempted dialogue: Ethan: Are you kidding? I’m going to tell everyone. You can’t hide this. (Enunciation: Clarity, Conviction)\n",
      "attempted idx: 0\n",
      "audio worker\n",
      "check audio tool call\n",
      "supervisor\n",
      "traveling\n",
      "audio worker\n",
      "check audio tool call\n",
      "supervisor\n",
      "traveling\n",
      "video worker\n",
      "check video tool call\n",
      "VIDEOWORKER PROMPT: 9s\n",
      "------------------------------\n",
      "INT. MONTAGUE MUSEUM – MODERN DAY. The camera pans over the opulent and richly-decorated room filled with artifacts from the Montague family legacy. ELIZABETH MONTAGUE, a strong-willed woman with a sharp expression, stands by a vintage display case, intense and furious. She faces ETHAN, a spirited, determined individual. The room echoes with tension as Elizabeth asserts her authority: “You know you can’t tell a soul, right?” Her commanding voice fills the air. Ethan, undeterred, counters with conviction, “Are you kidding? I’m going to tell everyone. You can’t hide this.” Their voices overlap with the ambiance of the historical setting, creating a powerful cinematic moment.\n",
      "generating vid\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n"
     ]
    }
   ],
   "source": [
    "members = [\"video_worker\",\"storyboard_worker\",\"audio_worker\"] #\"editor\"\n",
    "supervisor_options = members + [END]\n",
    "visitedAudioWorker = False\n",
    "class Supervisor_Router(TypedDict):\n",
    "    \"\"\"Worker to route to next to fulfill the user's request. If no workers are needed, route to END.\"\"\"\n",
    "\n",
    "    next: Literal[*supervisor_options]\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def go_next(state: MessagesState) -> Literal[*supervisor_options]:\n",
    "    global visitedAudioWorker\n",
    "    print(f\"traveling\")\n",
    "    if(state[\"next\"]==\"video_worker\" and not visitedAudioWorker):\n",
    "        visitedAudioWorker = True\n",
    "        return \"audio_worker\"\n",
    "    return state[\"next\"]\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_supervisor(state: MessagesState):\n",
    "    print(\"supervisor\")\n",
    "    messages = state[\"messages\"]\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a supervisor of a short film project and am in charge of a team of 4. You can delegate relevant tasks to any of these members: {members}.\"\n",
    "        \"Bob the video_worker is capable of generating high fidelity videos, but requires clear contextual information. Ryan the audio_worker is able to generate character\"\n",
    "        \"dialogue audio clips. Steve the storyboard_worker is able to analyze a given input script and break it down into fine details and generate character profiles.\"\n",
    "        \"\\nYou should ALWAYS ensure Steve has generated a STORYBOARD and character profiles for ALL characters analyzed in the storyboard tool response before anything else.\"\n",
    "        \"\\nIMPORTANT!!! MAKE SURE Ryan generates audio clips BEFORE Bob generates video clips. Generate a step-by-step plan from the following prompt and act on it.\"\n",
    "        \"\\nEXAMPLE PLAN: STEVE STORYBOARD -> STEVE CHARACTER PROFILES -> RYAN AUDIO CLIPS -> BOB VIDEOS\"\n",
    "        \"When responding, please output a JSON object that follows this schema:\\n\"\n",
    "        '{ \"next\": one of the allowed values: ' + \", \".join(supervisor_options) + \" }\\n\"\n",
    "        \"If no further workers are needed, output 'END' as the next step.\"\n",
    "    }\n",
    "    response = supervisor_llm.with_structured_output(Supervisor_Router).invoke(messages)\n",
    "    # Wrap the response in a valid message format\n",
    "    structured_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Routing to {response['next']}\"\n",
    "    }\n",
    "    return {\"messages\": [structured_message], \"next\": response[\"next\"]}\n",
    "\n",
    "def call_video_worker(state: MessagesState):\n",
    "    print(\"video worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Bob, a video worker. Process the given request accordingly. Note that you can only generate 5 second or 9 second videos.\\\n",
    "        If you need to generate further content, ensure the characters and the scene in the video are consistent by providing similar prompts.\\\n",
    "        Generate only ONE video at a time. Wait until you have received the filepath of the current video being generated before generating another. [Use Unique Prompts]\"\n",
    "    }\n",
    "    response = video_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_storyboard_worker(state: MessagesState):\n",
    "    print(\"storyboard worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are Steve, a storyboarder. Process the given request accordingly. You have access to two tools: a storyboard generator and a character profile\\\n",
    "        generator. Generate only ONE character profile at a time. You should pass in all character results from the storyboard generator into the character profile generator.\"\n",
    "    }\n",
    "    response = storyboard_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_audio_worker(state: MessagesState):\n",
    "    global fullDialogueString\n",
    "    print(\"audio worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Ryan, a character dialogue generator. Process the given request accordingly. You have access to one tool\\\n",
    "        which generates a dialogue audio clip for a SINGLE character talking. Parse this string once for each instance with a character talking generate audio:\"+ fullDialogueString\n",
    "    }\n",
    "    response = audio_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def check_video_tool_calls(state: MessagesState) -> Literal[\"video_tools\",\"supervisor\"]:\n",
    "    print(\"check video tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"video_tools\"\n",
    "    return \"supervisor\"\n",
    "\n",
    "def check_storyboard_tool_calls(state: MessagesState) -> Literal[\"storyboard_tools\",\"supervisor\"]:\n",
    "    print(\"check storyboard tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"storyboard_tools\"\n",
    "    return \"supervisor\"\n",
    "    \n",
    "def check_audio_tool_calls(state: MessagesState) -> Literal[\"audio_tools\",\"supervisor\"]:\n",
    "    print(\"check audio tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"audio_tools\"\n",
    "    return \"supervisor\"\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"supervisor\", call_supervisor)\n",
    "workflow.add_node(\"video_worker\", call_video_worker)\n",
    "workflow.add_node(\"video_tools\", video_tool_node)\n",
    "workflow.add_node(\"storyboard_worker\", call_storyboard_worker)\n",
    "workflow.add_node(\"storyboard_tools\", storyboard_tool_node)\n",
    "workflow.add_node(\"audio_worker\", call_audio_worker)\n",
    "workflow.add_node(\"audio_tools\", audio_tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    go_next,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"video_worker\",\n",
    "    check_video_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"storyboard_worker\",\n",
    "    check_storyboard_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"audio_worker\",\n",
    "    check_audio_tool_calls,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"video_tools\", 'video_worker')\n",
    "workflow.add_edge(\"storyboard_tools\",\"storyboard_worker\");\n",
    "workflow.add_edge(\"audio_tools\",\"audio_worker\");\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "generatingImg = False\n",
    "generatingVid = False\n",
    "# Use the agent\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Generate a STORYBOARD, AUDIO, AND VIDEO about the following scene: INT. MONTAGUE MUSEUM – MODERN DAYThe once-grand family home, now a tour-driven Hearst Castle-like museum.ELIZABETH MONTAGUE, intense and angry, argues with Ethan.ELIZABETHYou know you can’t tell a soul,right?ETHANAre you kidding? I’m going to telleveryone. You can’t hide this.\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29635ea7-bfbd-41f6-bfcd-a498d6171f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = client.generations.image.create(\n",
    "    prompt=\"sunglasses\",\n",
    "    image_ref=[\n",
    "      {\n",
    "        \"url\": \"https://storage.cdn-luma.com/dream_machine/7e4fe07f-1dfd-4921-bc97-4bcf5adea39a/video_0_thumb.jpg\",\n",
    "        \"weight\": 0.85\n",
    "      }\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
