{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a0b91f-1ab1-423d-890d-3c0f4e3c6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir('Lib/site-packages')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "import ffmpeg\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import uuid\n",
    "#import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from lumaai import LumaAI\n",
    "from typing import Literal, TypedDict\n",
    "from elevenlabs.client import ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7c9450-b7f9-49e2-846a-03b8bead1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUMA\n",
    "client = LumaAI(\n",
    "    auth_token=os.environ.get(\"LUMAAI_API_KEY\"),\n",
    ")\n",
    "#OPENAI\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "#ELEVENLABS\n",
    "elevenlabs_client = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "#LANGCHAIN llms\n",
    "supervisor_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "video_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "storyboard_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "audio_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "#editor_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "generatingVid = False\n",
    "fullDialogueString = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dc3f3-a4e8-4fd0-9ffc-b7244c81da71",
   "metadata": {},
   "source": [
    "## TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bd710-06c9-432d-9602-c38a3f7a5fba",
   "metadata": {},
   "source": [
    "### Video Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9958d677-52aa-48e2-a95b-5e2278d3254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMAS\n",
    "class video_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a video using text input and returns a filepath to the video\"\"\"\n",
    "    vid_prompt: str = Field(..., description=\"The textual prompt used in generating the video\")\n",
    "    use_9s: bool = Field(..., description=\"Whether to generate a 9 second long video. If set to FALSE, this will generate a 5 second long video\")\n",
    "\n",
    "\n",
    "@tool(\"video_gen_tool\",args_schema=video_gen_schema)   \n",
    "def generate_vid(vid_prompt: str, use_9s: bool) -> str:\n",
    "    global generatingVid\n",
    "    if(generatingVid):\n",
    "        return \"Failed to generate video, there is currently another video being generated.\"\n",
    "    dur = \"5s\"\n",
    "    if(use_9s):\n",
    "        dur = \"9s\"\n",
    "    print(f\"VIDEOWORKER PROMPT: {dur}\\n------------------------------\\n\" + vid_prompt)\n",
    "    generatingVid = True\n",
    "    generation = client.generations.create(\n",
    "        prompt=vid_prompt,\n",
    "        model=\"ray-2\",\n",
    "        resolution=\"720p\",\n",
    "        duration=dur\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating vid\")\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(5)\n",
    "    video_url = generation.assets.video\n",
    "    # download the video\n",
    "    response = requests.get(video_url, stream=True)\n",
    "    with open(f'staticVid1/{generation.id}.mp4', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Video generated in staticVid1/{generation.id}.mp4\")\n",
    "    generatingVid = False\n",
    "    return f\"Video generated in staticVid1/{generation.id}.mp4\"\n",
    "\n",
    "#class extend_video_schema(BaseModel):\n",
    "video_tools = [generate_vid]\n",
    "video_tool_node = ToolNode(video_tools)\n",
    "video_worker = video_gen_llm.bind_tools(video_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5b6e-939f-4b35-b636-9e8842e04e44",
   "metadata": {},
   "source": [
    "### Storyboard Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91838bf-2756-46e3-955b-8689016710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMA\n",
    "class step_by_step_output_schema(BaseModel):\n",
    "    \"\"\"Prints a storyboard for the user to view in string format\"\"\"\n",
    "    story_description: str = Field(..., description=\"A 200-250 word description of the story\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of each character in the scene\")\n",
    "    background_details: str = Field(..., description=\"A 50-100 description of the scene\")\n",
    "    auditory_details: str = Field(..., description=\"A 50-100 description of the voice profile of each character\")\n",
    "    dialogue_details: str = Field(..., description=\"The parts of the dialogue that require enunciation and emotion\")\n",
    "    num_characters: int = Field(..., description=\"The number of unique characters present in this scene\")\n",
    "    pure_dialogue: str = Field(..., description=\"The extracted dialogue from the input scene with character name appended before. Within the dialogue, indicate dialogue details that require enunciation and emotion with descriptors in parentheses Format: {CharacterName}: {Dialogue (Enunciation) Dialogue Detail}\")\n",
    "    dialogue_instances: int = Field(..., description=\"The number of distinct non-continuous dialogue instances present in this scene\")\n",
    "charProfileQueue = 0\n",
    "dialogueQueue = 0\n",
    "@tool(\"storyboard_tool\",args_schema=step_by_step_output_schema)\n",
    "def generate_storyboard(story_description: str,character_details: str,background_details: str,auditory_details: str,dialogue_details: str, num_characters: int,pure_dialogue: str, dialogue_instances: int) -> str:\n",
    "    global fullDialogueString\n",
    "    global charProfileQueue\n",
    "    global dialogueQueue\n",
    "    print(\"storyboarding\")\n",
    "    temp_storyboard = \"STORY ANALYSIS\\n------------------------------\\n\"+story_description+\"\\nCHARACTERS\\n------------------------------\\n\"+character_details\n",
    "    temp_storyboard+=\"\\nBACKGROUND\\n------------------------------\\n\"+background_details+\"\\nAUDIO\\n------------------------------\\n\"+auditory_details+\"\\nDIALOGUE\\n------------------------------\\n\"\n",
    "    temp_storyboard+=dialogue_details+\"\\nNumber of characters\\n------------------------------\\n\"+ str(num_characters)+\"\\nPure Dialogue\\n------------------------------\\n\" + pure_dialogue\n",
    "    temp_storyboard+=\"\\nUnique Dialogue Instances\\n------------------------------\\n\"+ str(dialogue_instances)\n",
    "    print(temp_storyboard)\n",
    "    fullDialogueString = pure_dialogue\n",
    "    charProfileQueue = num_characters\n",
    "    dialogueQueue = dialogue_instances\n",
    "    return temp_storyboard\n",
    "\n",
    "class character_profile_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a character profile for a character and returns the url\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character, taken from the script\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of the character in the scene, taken from the script\")\n",
    "\n",
    "@tool(\"character_profile_tool\",args_schema=character_profile_gen_schema)\n",
    "def generate_character_profile(character_name: str, character_details: str)->str:\n",
    "    global charProfileQueue\n",
    "    if(charProfileQueue<=0):\n",
    "        return \"Already generated character profiles!\"\n",
    "    generation = client.generations.image.create(\n",
    "      prompt=\"Generate a hyperrealistic, front-facing portrait \\\n",
    "      The image should feature perfectly even, diffused lighting that completely\\\n",
    "      eliminates any shadows on the face. Use a direct, center-camera angle against a neutral,\\\n",
    "      unobtrusive background to ensure absolute consistency. Focus on lifelike details with natural \\\n",
    "      skin textures and realistic, balanced color tones, making the portrait suitable as a reference\\\n",
    "      for video character consistency.: \"+character_name+\", \"+character_details,\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating char profile for: \" + character_name)\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(2)\n",
    "    image_url = generation.assets.image\n",
    "    print(\"image_url: \" +image_url)\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    with open(f'charRef/{generation.id}.jpg', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Image generated in charRef/{generation.id}.jpg\")\n",
    "    charProfileQueue-=1;\n",
    "    return f\"Profile generated: {image_url}\"\n",
    "\n",
    "storyboard_tools = [generate_storyboard,generate_character_profile]\n",
    "storyboard_tool_node = ToolNode(storyboard_tools)\n",
    "storyboard_worker = storyboard_llm.bind_tools(storyboard_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf12443-0259-452e-bf07-27d0d57f9593",
   "metadata": {},
   "source": [
    "### Audio Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd454937-f86f-4a39-84fa-e8671ce437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dialogue_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a dialogue mp3 clip and returns the filepath to the audio\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character talking\")\n",
    "    character_profile: str = Field(..., description=\"The link to the generated character profile of the character who is talking. Format: {https://storage.cdn-luma.com/dream_machine/../.._result.jpg}\")\n",
    "    dialogue_text: str = Field(..., description=\"The dialogue text of a SINGLE character for a particular scene.\")\n",
    "    voice_idx: int = Field(..., description=\"Out of the following voice ids, choose the index of the one that best suits the character who is speaking:\\\n",
    "    [{29vD33N1CtxCmqQRPOHJ: Male young and nervous},{N2lVS1w4EtoT3dr4eOWO: Male booming and imposing},\\\n",
    "    {21m00Tcm4TlvDq8ikWAM: Female elegant and slightly teasing}]\")\n",
    "chronological_dialogue_duration = []\n",
    "chrono_character=[]\n",
    "character_profiles_chrono=[]\n",
    "@tool(\"dialogue_gen_tool\",args_schema=dialogue_gen_schema)\n",
    "def generate_dialogue(character_name: str,character_profile: str,dialogue_text: str, voice_idx: int) -> str:\n",
    "    global chronological_dialogue_duration\n",
    "    global chrono_character\n",
    "    global character_profiles_chrono\n",
    "    global dialogueQueue\n",
    "    print(\"attempted dialogue: \" +dialogue_text+\"\\nattempted idx: \" + str(voice_idx))\n",
    "    if(dialogueQueue<=0):\n",
    "        return \"Already generated all dialogue!\"\n",
    "    voice_ids = [\"29vD33N1CtxCmqQRPOHJ\",\"N2lVS1w4EtoT3dr4eOWO\",\"21m00Tcm4TlvDq8ikWAM\"]\n",
    "    eleven_response = elevenlabs_client.text_to_speech.convert(\n",
    "        voice_id=voice_ids[voice_idx],\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_44100_128\",\n",
    "        text=dialogue_text,\n",
    "        model_id=\"eleven_turbo_v2\",\n",
    "    )\n",
    "    \n",
    "    # Save the file into the raw_audio directory\n",
    "    raw_audio_dir = \"staticAudio1\"\n",
    "    os.makedirs(raw_audio_dir, exist_ok=True)\n",
    "    file_path = os.path.join(raw_audio_dir, f\"{uuid.uuid4()}.mp3\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        for chunk in eleven_response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    duration = 0\n",
    "    try:\n",
    "        probe = ffmpeg.probe(file_path)\n",
    "        duration = math.ceil(float(probe['format']['duration']))\n",
    "        chronological_dialogue_duration.append(duration)\n",
    "        chrono_character.append(character_name)\n",
    "        character_profiles_chrono.append(character_profile)\n",
    "        print(\"duration: \" + str(duration) + \"\\ncharacterSpeaking: \" + character_name +\"\\ncharProfile: \" + character_profile)\n",
    "        dialogueQueue-=1;\n",
    "        return file_path\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"Error probing file:\", e.stderr)\n",
    "        raise e\n",
    "    \n",
    "audio_tools = [generate_dialogue]\n",
    "audio_tool_node = ToolNode(audio_tools)\n",
    "audio_worker = audio_gen_llm.bind_tools(audio_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a750a2f-6132-407a-b409-57ce8329ca93",
   "metadata": {},
   "source": [
    "### Editor Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76812a2d-d0f4-4679-91e2-ed9e49ede09d",
   "metadata": {},
   "source": [
    "## RUNNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcbeb42-ff84-4b08-89ac-e84f2471fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor\n",
      "traveling\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "storyboarding\n",
      "STORY ANALYSIS\n",
      "------------------------------\n",
      "In the grand halls of Montague Museum, Elizabeth Montague and Ethan stand amidst vintage furniture, arguing heatedly. The air is thick with tension, echoing the house's storied past. Once a noble family estate, the Montague home has now transformed into a public museum that draws tourists eager to glimpse into the opulence of yesteryears. The elegant decor and preserved artifacts of the past juxtapose with the fiery confrontation unfolding between Elizabeth and Ethan, set against the backdrop of family secrets threatened to be revealed.\n",
      "\n",
      "Elizabeth Montague, the last of the Montague lineage, is visibly distraught. Her sharp features mirror her stern demeanor as she holds the weight of her family's legacy on her shoulders. Desperation wraps around her like a cloak as she demands Ethan's silence about a secret scandal that could potentially ruin her family name once exposed to the world.\n",
      "\n",
      "Ethan, a younger man with a rebellious spirit, challenges Elizabeth's authority—refusing to be complicit in her demand for secrecy. Caught in a moral dilemma, Ethan believes the truth should prevail, even if it could shatter public perceptions. Their conflict spirals in the historic grand hall, a place where countless family histories above walls watch them collide in their moral standoff.\n",
      "CHARACTERS\n",
      "------------------------------\n",
      "Elizabeth Montague is a woman in her late 40s, epitomizing the grace and rigor of aristocracy. Her demeanor is intense and determined as she strives to uphold the dignity associated with the Montague family name. Clad in an elegantly conservative suit, she embodies the essence of her heritage. Her piercing gaze and tightly set lips are unmistakable indicators of the rigidity with which she carries herself. Despite her composed exterior, her hands tremble slightly, suggesting an undercurrent of anxiety and vulnerability beneath the surface. Her authoritative voice commands attention, and she is not one to let go of control easily. As the custodian of the family's secrets and the director of the museum, Elizabeth feels the heavy burden of preserving the image of the Montague dynasty.\n",
      "\n",
      "Ethan, in contrast, is a man in his early 30s dressed in casual contemporary attire, standing several paces away from Elizabeth. His youthful defiance is characterized by an unkempt look, and his eyes exhibit a mix of determination and sympathy. Despite his relaxed appearance, there's an intensity to his presence that challenges Elizabeth's authority. With a background unrelated to the Montague family, he represents a voice of change, standing steadfast in his belief that transparency is paramount. His defiant posture complements his audacity to voice truths that many would shy away from, marking him as both an antagonist and a refreshing force against the staunch traditions upheld by Elizabeth.\n",
      "BACKGROUND\n",
      "------------------------------\n",
      "The Montague Museum is filled with lavish decor reminiscent of the early 20th century - ornate wooden furniture, chandeliers, and family portraits lining walls. It encapsulates opulence, with each room a testament to grandeur now open to the public, yet rich in private history.\n",
      "AUDIO\n",
      "------------------------------\n",
      "Elizabeth's voice is sharp and commanding, often carrying an edge due to her frustration and urgency. Her words cut through the air with precision and a hint of desperation. Ethan's voice, in contrast, is assertive but casual, marked by his insistence on truth and moral integrity, resonating sincerity and rebel audacity through his even-toned yet compelling speech.\n",
      "DIALOGUE\n",
      "------------------------------\n",
      "Elizabeth's lines are enunciated with intensity, \"You know you can’t tell a soul, right?\" emphasizing secrecy and urgency. Her voice brims with frustration and a slight tremor of desperation. Ethan's line, \"Are you kidding? I’m going to tell everyone. You can’t hide this.\" requires firmness and defiance, capturing the essence of his moral conviction and rebellion.\n",
      "Number of characters\n",
      "------------------------------\n",
      "2\n",
      "Pure Dialogue\n",
      "------------------------------\n",
      "Elizabeth: You know you can’t tell a soul, (Intense) right? Ethan: (Defiant) Are you kidding? I’m going to tell everyone. (Rebellious) You can’t hide this.\n",
      "Unique Dialogue Instances\n",
      "------------------------------\n",
      "1\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "generating char profile for: Ethan\n",
      "generating char profile for: Elizabeth Montague\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queuedDreaming, state:queued\n",
      "\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:completed\n",
      "Dreaming, state:dreaming\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/c5c9af14-975b-4f25-b4f4-0370a808a3c7/c7fc5f0b-6c71-40a8-9dc1-fd77b6289bf4_result.jpg\n",
      "Image generated in charRef/fa2188d1-c547-45fb-bc9a-cd7902ee9410.jpg\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:completed\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/557e282c-d8c4-41a0-8ad1-4694d974b2f9/94a59a8d-f23b-4360-a5f5-de2eb1fc91b8_result.jpg\n",
      "Image generated in charRef/d1cf07b5-b793-4f14-beca-b3d49dc8cc70.jpg\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "supervisor\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 160\u001b[0m\n\u001b[0;32m    158\u001b[0m generatingVid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Use the agent\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate a STORYBOARD, AUDIO, AND VIDEO about the following scene: INT. MONTAGUE MUSEUM – MODERN DAYThe once-grand family home, now a tour-driven Hearst Castle-like museum.ELIZABETH MONTAGUE, intense and angry, argues with Ethan.ELIZABETHYou know you can’t tell a soul,right?ETHANAre you kidding? I’m going to telleveryone. You can’t hide this.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m final_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2069\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2071\u001b[0m     config,\n\u001b[0;32m   2072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2073\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2074\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2075\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2076\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2077\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2078\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2080\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mD:\\Hackathoncool\\CreativeControl\\Lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m, in \u001b[0;36mcall_supervisor\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     35\u001b[0m response \u001b[38;5;241m=\u001b[39m supervisor_llm\u001b[38;5;241m.\u001b[39mwith_structured_output(Supervisor_Router)\u001b[38;5;241m.\u001b[39minvoke(messages)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Wrap the response in a valid message format\u001b[39;00m\n\u001b[0;32m     37\u001b[0m structured_message \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRouting to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m }\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [structured_message], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m: response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'next'",
      "\u001b[0mDuring task with name 'supervisor' and id '18581cbe-e77d-a656-014b-c297132caa95'"
     ]
    }
   ],
   "source": [
    "members = [\"video_worker\",\"storyboard_worker\",\"audio_worker\"] #\"editor\"\n",
    "supervisor_options = members + [END]\n",
    "visitedAudioWorker = False\n",
    "class Supervisor_Router(TypedDict):\n",
    "    \"\"\"Worker to route to next to fulfill the user's request. If no workers are needed, route to END.\"\"\"\n",
    "\n",
    "    next: Literal[*supervisor_options]\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def go_next(state: MessagesState) -> Literal[*supervisor_options]:\n",
    "    global visitedAudioWorker\n",
    "    print(f\"traveling\")\n",
    "    if(state[\"next\"]==\"video_worker\" and not visitedAudioWorker):\n",
    "        visitedAudioWorker = True\n",
    "        return \"audio_worker\"\n",
    "    return state[\"next\"]\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_supervisor(state: MessagesState):\n",
    "    print(\"supervisor\")\n",
    "    messages = state[\"messages\"]\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a supervisor of a short film project and am in charge of a team of 4. You can delegate relevant tasks to any of these members: {members}.\"\n",
    "        \"Bob the video_worker is capable of generating high fidelity videos, but requires clear contextual information. Ryan the audio_worker is able to generate character\"\n",
    "        \"dialogue audio clips. Steve the storyboard_worker is able to analyze a given input script and break it down into fine details and generate character profiles.\"\n",
    "        \"\\nYou should ALWAYS ensure Steve has generated a STORYBOARD and character profiles for ALL characters analyzed in the storyboard tool response before anything else.\"\n",
    "        \"\\nIMPORTANT!!! MAKE SURE Ryan generates audio clips BEFORE Bob generates video clips. Generate a step-by-step plan from the following prompt and act on it.\"\n",
    "        \"\\nEXAMPLE PLAN: STEVE STORYBOARD -> STEVE CHARACTER PROFILES -> RYAN AUDIO CLIPS -> BOB VIDEOS\"\n",
    "        \"When responding, please output a JSON object that follows this schema:\\n\"\n",
    "        '{ \"next\": one of the allowed values: ' + \", \".join(supervisor_options) + \" }\\n\"\n",
    "        \"If no further workers are needed, output 'END' as the next step.\"\n",
    "    }\n",
    "    response = supervisor_llm.with_structured_output(Supervisor_Router).invoke(messages)\n",
    "    # Wrap the response in a valid message format\n",
    "    structured_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Routing to {response['next']}\"\n",
    "    }\n",
    "    return {\"messages\": [structured_message], \"next\": response[\"next\"]}\n",
    "\n",
    "def call_video_worker(state: MessagesState):\n",
    "    print(\"video worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Bob, a video worker. Process the given request accordingly. Note that you can only generate 5 second or 9 second videos.\\\n",
    "        If you need to generate further content, ensure the characters and the scene in the video are consistent by providing similar prompts.\\\n",
    "        Generate only ONE video at a time. Wait until you have received the filepath of the current video being generated before generating another. [Use Unique Prompts]\"\n",
    "    }\n",
    "    response = video_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_storyboard_worker(state: MessagesState):\n",
    "    print(\"storyboard worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are Steve, a storyboarder. Process the given request accordingly. You have access to two tools: a storyboard generator and a character profile\\\n",
    "        generator. Generate only ONE character profile at a time. You should pass in all character results from the storyboard generator into the character profile generator.\"\n",
    "    }\n",
    "    response = storyboard_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_audio_worker(state: MessagesState):\n",
    "    global fullDialogueString\n",
    "    print(\"audio worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Ryan, a character dialogue generator. Process the given request accordingly. You have access to one tool\"\n",
    "        \"which generates a dialogue audio clip for a SINGLE character talking ONLY AS PER THE CHRONOLOGICAL OREDER of the storyboard generated by STEVE.\"\n",
    "        \"Check if you have already generated a piece of dialogue. If you have, don't generate it again.\"\n",
    "        \"Parse this string once for each instance with a character talking generate audio:\"+ fullDialogueString\n",
    "    }\n",
    "    response = audio_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def check_video_tool_calls(state: MessagesState) -> Literal[\"video_tools\",\"supervisor\"]:\n",
    "    print(\"check video tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"video_tools\"\n",
    "    return \"supervisor\"\n",
    "\n",
    "def check_storyboard_tool_calls(state: MessagesState) -> Literal[\"storyboard_tools\",\"supervisor\"]:\n",
    "    print(\"check storyboard tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"storyboard_tools\"\n",
    "    return \"supervisor\"\n",
    "    \n",
    "def check_audio_tool_calls(state: MessagesState) -> Literal[\"audio_tools\",\"supervisor\"]:\n",
    "    print(\"check audio tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"audio_tools\"\n",
    "    return \"supervisor\"\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"supervisor\", call_supervisor)\n",
    "workflow.add_node(\"video_worker\", call_video_worker)\n",
    "workflow.add_node(\"video_tools\", video_tool_node)\n",
    "workflow.add_node(\"storyboard_worker\", call_storyboard_worker)\n",
    "workflow.add_node(\"storyboard_tools\", storyboard_tool_node)\n",
    "workflow.add_node(\"audio_worker\", call_audio_worker)\n",
    "workflow.add_node(\"audio_tools\", audio_tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    go_next,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"video_worker\",\n",
    "    check_video_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"storyboard_worker\",\n",
    "    check_storyboard_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"audio_worker\",\n",
    "    check_audio_tool_calls,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"video_tools\", 'video_worker')\n",
    "workflow.add_edge(\"storyboard_tools\",\"storyboard_worker\");\n",
    "workflow.add_edge(\"audio_tools\",\"audio_worker\");\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "generatingImg = False\n",
    "generatingVid = False\n",
    "# Use the agent\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Generate a STORYBOARD, AUDIO, AND VIDEO about the following scene: INT. MONTAGUE MUSEUM – MODERN DAYThe once-grand family home, now a tour-driven Hearst Castle-like museum.ELIZABETH MONTAGUE, intense and angry, argues with Ethan.ELIZABETHYou know you can’t tell a soul,right?ETHANAre you kidding? I’m going to telleveryone. You can’t hide this.\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29635ea7-bfbd-41f6-bfcd-a498d6171f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
