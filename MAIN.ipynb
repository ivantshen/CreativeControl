{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a0b91f-1ab1-423d-890d-3c0f4e3c6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir('Lib/site-packages')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "import ffmpeg\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import uuid\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from lumaai import LumaAI\n",
    "from typing import Literal, TypedDict\n",
    "from elevenlabs.client import ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7c9450-b7f9-49e2-846a-03b8bead1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUMA\n",
    "client = LumaAI(\n",
    "    auth_token=os.environ.get(\"LUMAAI_API_KEY\"),\n",
    ")\n",
    "#OPENAI\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "#ELEVENLABS\n",
    "elevenlabs_client = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "#LANGCHAIN llms\n",
    "supervisor_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "video_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "storyboard_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "audio_gen_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "editor_llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "generatingVid = False\n",
    "fullDialogueString = \"\"\n",
    "chronological_dialogue_duration = []\n",
    "chronological_dialogue_mp3_path = []\n",
    "chronological_video_mp4_path = []\n",
    "chrono_character=[]\n",
    "character_profiles_chrono=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dc3f3-a4e8-4fd0-9ffc-b7244c81da71",
   "metadata": {},
   "source": [
    "## TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bd710-06c9-432d-9602-c38a3f7a5fba",
   "metadata": {},
   "source": [
    "### Video Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6845f-1e09-46a7-ba7d-e944643b671c",
   "metadata": {},
   "source": [
    "#SCHEMAS\n",
    "class video_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a video using text input and returns a filepath to the video\"\"\"\n",
    "    vid_prompt: str = Field(..., description=\"The textual prompt used in generating the video\")\n",
    "    use_9s: bool = Field(..., description=\"Whether to generate a 9 second long video. If set to FALSE, this will generate a 5 second long video\")\n",
    "\n",
    "@tool(\"video_gen_tool\",args_schema=video_gen_schema)   \n",
    "def generate_vid(vid_prompt: str, use_9s: bool) -> str:\n",
    "    global generatingVid\n",
    "    if(generatingVid):\n",
    "        return \"Failed to generate video, there is currently another video being generated.\"\n",
    "    dur = \"5s\"\n",
    "    if(use_9s):\n",
    "        dur = \"9s\"\n",
    "    print(f\"VIDEOWORKER PROMPT: {dur}\\n------------------------------\\n\" + vid_prompt)\n",
    "    generatingVid = True\n",
    "    generation = client.generations.create(\n",
    "        prompt=vid_prompt,\n",
    "        model=\"ray-2\",\n",
    "        resolution=\"720p\",\n",
    "        duration=dur\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating vid\")\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(5)\n",
    "    video_url = generation.assets.video\n",
    "    # download the video\n",
    "    response = requests.get(video_url, stream=True)\n",
    "    with open(f'staticVid1/{generation.id}.mp4', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Video generated in staticVid1/{generation.id}.mp4\")\n",
    "    generatingVid = False\n",
    "    return f\"Video generated in staticVid1/{generation.id}.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9958d677-52aa-48e2-a95b-5e2278d3254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMAS\n",
    "currentDialogueIdx = 0\n",
    "class video_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a video using text input and returns a filepath to the video\"\"\"\n",
    "    start_keyframe_prompt: str = Field(..., description=\"200 words about start keyframe details\")\n",
    "    end_keyframe_prompt: str = Field(..., description=\"200 words about end keyframe details\")\n",
    "    vid_prompt: str = Field(..., description=\"200 words about details of the specified character talking\")\n",
    "    use_9s: bool = Field(..., description=\"Whether to generate a 9 second long video. If set to FALSE, this will generate a 5 second long video\")\n",
    "\n",
    "currentlyGeneratingDialogue = False\n",
    "@tool(\"video_gen_tool\",args_schema=video_gen_schema)   \n",
    "def generate_vid(start_keyframe_prompt:str, end_keyframe_prompt:str, vid_prompt: str, use_9s: bool) -> str:\n",
    "    global currentDialogueIdx\n",
    "    global currentlyGeneratingDialogue\n",
    "    global character_profiles_chrono\n",
    "    global chrono_character\n",
    "    global chronological_video_mp4_path\n",
    "    numClipsToGen = len(character_profiles_chrono)\n",
    "    if(currentDialogueIdx>=numClipsToGen):\n",
    "        return \"Finished generating all dialogue clips.\"\n",
    "    while(currentlyGeneratingDialogue):\n",
    "        print(\"secondary gen frozen, waiting on completion of first\")\n",
    "        time.sleep(5)\n",
    "    currentlyGeneratingDialogue=True\n",
    "    dur = \"5s\"\n",
    "    if(use_9s):\n",
    "        dur = \"9s\"\n",
    "    print(f\"START KEYFRAME PROMPT: \"+ start_keyframe_prompt)\n",
    "    start_keyframe_generation = client.generations.image.create(\n",
    "        prompt=start_keyframe_prompt,\n",
    "        image_ref=[\n",
    "          {\n",
    "            \"url\": character_profiles_chrono[currentDialogueIdx],\n",
    "            \"weight\": 0.7\n",
    "          }\n",
    "        ]\n",
    "    )\n",
    "    start_keyframe_completed = False\n",
    "    while not start_keyframe_completed:\n",
    "      start_keyframe_generation = client.generations.get(id=start_keyframe_generation.id)\n",
    "      if start_keyframe_generation.state == \"completed\":\n",
    "        start_keyframe_completed = True\n",
    "      elif start_keyframe_generation.state == \"failed\":\n",
    "        currentlyGeneratingDialogue=False\n",
    "        print(\"FAILED IMG\")\n",
    "        raise RuntimeError(f\"Generation failed: {start_keyframe_generation.failure_reason}\")\n",
    "      print(\"Start Keyframe Dreaming, state:\" + start_keyframe_generation.state)\n",
    "      time.sleep(2)\n",
    "    start_keyframe_image_url = start_keyframe_generation.assets.image\n",
    "    print(\"start_keyframe_image_url: \" +start_keyframe_image_url)\n",
    "    start_keyframe_response = requests.get(start_keyframe_image_url, stream=True)\n",
    "    with open(f'staticStartKeyFrame/{currentDialogueIdx}.jpg', 'wb') as file:\n",
    "        file.write(start_keyframe_response.content)\n",
    "    print(f\"Image generated in staticStartKeyFrame/{currentDialogueIdx}.jpg\")\n",
    "\n",
    "    ###END ME\n",
    "\n",
    "    print(f\"END KEYFRAME PROMPT: \"+ end_keyframe_prompt)\n",
    "    end_keyframe_generation = client.generations.image.create(\n",
    "        prompt=end_keyframe_prompt,\n",
    "        image_ref=[\n",
    "          {\n",
    "            \"url\": character_profiles_chrono[currentDialogueIdx],\n",
    "            \"weight\": 0.7\n",
    "          }\n",
    "        ]\n",
    "    )\n",
    "    end_keyframe_completed = False\n",
    "    while not end_keyframe_completed:\n",
    "      end_keyframe_generation = client.generations.get(id=end_keyframe_generation.id)\n",
    "      if end_keyframe_generation.state == \"completed\":\n",
    "        end_keyframe_completed = True\n",
    "      elif end_keyframe_generation.state == \"failed\":\n",
    "        currentlyGeneratingDialogue=False\n",
    "        print(\"FAILED IMG\")\n",
    "        raise RuntimeError(f\"Generation failed: {end_keyframe_generation.failure_reason}\")\n",
    "      print(\"End Keyframe Dreaming, state:\" + end_keyframe_generation.state)\n",
    "      time.sleep(2)\n",
    "    end_keyframe_image_url = end_keyframe_generation.assets.image\n",
    "    print(\"end_keyframe_image_url: \" +end_keyframe_image_url)\n",
    "    end_keyframe_response = requests.get(end_keyframe_image_url, stream=True)\n",
    "    with open(f'staticEndKeyFrame/{currentDialogueIdx}.jpg', 'wb') as file:\n",
    "        file.write(end_keyframe_response.content)\n",
    "    print(f\"Image generated in staticEndKeyFrame/{currentDialogueIdx}.jpg\")\n",
    "    \n",
    "    print(f\"VIDEOWORKER PROMPT: {dur}\\n------------------------------\\n\" + vid_prompt)\n",
    "    generation = client.generations.create(\n",
    "        prompt=vid_prompt,\n",
    "        keyframes={\n",
    "          \"frame0\": {\n",
    "            \"type\": \"image\",\n",
    "            \"url\": start_keyframe_image_url\n",
    "          },\n",
    "          \"frame1\": {\n",
    "            \"type\": \"image\",\n",
    "            \"url\": end_keyframe_image_url\n",
    "          }\n",
    "        },\n",
    "        model=\"ray-2\",\n",
    "        resolution=\"720p\",\n",
    "        duration=dur\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating vid\")\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        currentlyGeneratingDialogue=False\n",
    "        print(\"FAILED VID\")\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(5)\n",
    "    video_url = generation.assets.video\n",
    "    # download the video\n",
    "    response = requests.get(video_url, stream=True)\n",
    "    with open(f'staticVid1/{currentDialogueIdx}.mp4', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Video generated in staticVid1/{currentDialogueIdx}.mp4\")\n",
    "    chronological_video_mp4_path.append(f'staticVid1/{currentDialogueIdx}.mp4')\n",
    "    currentDialogueIdx+=1\n",
    "    currentlyGeneratingDialogue=False\n",
    "    return f\"Video generated in staticVid1/{currentDialogueIdx}.mp4\"\n",
    "\n",
    "#class extend_video_schema(BaseModel):\n",
    "video_tools = [generate_vid]\n",
    "video_tool_node = ToolNode(video_tools)\n",
    "video_worker = video_gen_llm.bind_tools(video_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5b6e-939f-4b35-b636-9e8842e04e44",
   "metadata": {},
   "source": [
    "### Storyboard Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91838bf-2756-46e3-955b-8689016710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMA\n",
    "class step_by_step_output_schema(BaseModel):\n",
    "    \"\"\"Prints a storyboard for the user to view in string format\"\"\"\n",
    "    story_description: str = Field(..., description=\"A 200-250 word description of the story\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of each character in the scene\")\n",
    "    background_details: str = Field(..., description=\"A 50-100 description of the scene\")\n",
    "    auditory_details: str = Field(..., description=\"A 50-100 description of the voice profile of each character\")\n",
    "    dialogue_details: str = Field(..., description=\"The parts of the dialogue that require enunciation and emotion\")\n",
    "    num_characters: int = Field(..., description=\"The number of unique characters present in this scene\")\n",
    "    pure_dialogue: str = Field(..., description=\"The extracted dialogue from the input scene with character name appended before. Within the dialogue, indicate dialogue details that require enunciation and emotion with descriptors in parentheses Format: {CharacterName}: {Dialogue (Enunciation) Dialogue Detail}\")\n",
    "    dialogue_instances: int = Field(..., description=\"The number of distinct dialogue instances present in this scene\")\n",
    "charProfileQueue = 0\n",
    "dialogueQueue = 0\n",
    "@tool(\"storyboard_tool\",args_schema=step_by_step_output_schema)\n",
    "def generate_storyboard(story_description: str,character_details: str,background_details: str,auditory_details: str,dialogue_details: str, num_characters: int,pure_dialogue: str, dialogue_instances: int) -> str:\n",
    "    global fullDialogueString\n",
    "    global charProfileQueue\n",
    "    global dialogueQueue\n",
    "    print(\"storyboarding\")\n",
    "    temp_storyboard = \"STORY ANALYSIS\\n------------------------------\\n\"+story_description+\"\\nCHARACTERS\\n------------------------------\\n\"+character_details\n",
    "    temp_storyboard+=\"\\nBACKGROUND\\n------------------------------\\n\"+background_details+\"\\nAUDIO\\n------------------------------\\n\"+auditory_details+\"\\nDIALOGUE\\n------------------------------\\n\"\n",
    "    temp_storyboard+=dialogue_details+\"\\nNumber of characters\\n------------------------------\\n\"+ str(num_characters)+\"\\nPure Dialogue\\n------------------------------\\n\" + pure_dialogue\n",
    "    temp_storyboard+=\"\\nUnique Dialogue Instances\\n------------------------------\\n\"+ str(dialogue_instances)\n",
    "    print(temp_storyboard)\n",
    "    fullDialogueString = pure_dialogue\n",
    "    charProfileQueue = num_characters\n",
    "    dialogueQueue = dialogue_instances\n",
    "    return temp_storyboard\n",
    "\n",
    "class character_profile_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a character profile for a character and returns the url\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character, taken from the script\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of the character in the scene, taken from the script\")\n",
    "charProfileIdx = 0\n",
    "generatingCharProfile = False\n",
    "@tool(\"character_profile_tool\",args_schema=character_profile_gen_schema)\n",
    "def generate_character_profile(character_name: str, character_details: str)->str:\n",
    "    global charProfileQueue\n",
    "    global charProfileIdx\n",
    "    global generatingCharProfile\n",
    "    if(charProfileQueue<=0):\n",
    "        return \"Already generated character profiles!\"\n",
    "    while(generatingCharProfile):\n",
    "        time.sleep(5)\n",
    "        print(\"paused char profile gen, waiting for first generation to complete\")\n",
    "    generatingCharProfile = True\n",
    "    generation = client.generations.image.create(\n",
    "      prompt=\"Generate a hyperrealistic, front-facing portrait \\\n",
    "      The image should feature perfectly even, diffused lighting that completely\\\n",
    "      eliminates any shadows on the face. Use a direct, center-camera angle against a neutral,\\\n",
    "      unobtrusive background to ensure absolute consistency. Focus on lifelike details with natural \\\n",
    "      skin textures and realistic, balanced color tones, making the portrait suitable as a reference\\\n",
    "      for video character consistency.: \"+character_name+\", \"+character_details,\n",
    "    )\n",
    "    completed = False\n",
    "    print(\"generating char profile for: \" + character_name)\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        generatingCharProfile = False\n",
    "        print(\"FAILED IMG\")\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming, state:\" + generation.state)\n",
    "      time.sleep(2)\n",
    "    image_url = generation.assets.image\n",
    "    print(\"image_url: \" +image_url)\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    with open(f'charRef/{charProfileIdx}.jpg', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Image generated in charRef/{charProfileIdx}.jpg\")\n",
    "    charProfileQueue-=1\n",
    "    charProfileIdx+=1\n",
    "    generatingCharProfile = False\n",
    "    return f\"Profile generated: {image_url}\"\n",
    "\n",
    "storyboard_tools = [generate_storyboard,generate_character_profile]\n",
    "storyboard_tool_node = ToolNode(storyboard_tools)\n",
    "storyboard_worker = storyboard_llm.bind_tools(storyboard_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf12443-0259-452e-bf07-27d0d57f9593",
   "metadata": {},
   "source": [
    "### Audio Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd454937-f86f-4a39-84fa-e8671ce437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dialogue_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a dialogue mp3 clip and returns the filepath to the audio\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character talking\")\n",
    "    character_profile: str = Field(..., description=\"The link to the generated character profile of the character who is talking. Format: {https://storage.cdn-luma.com/dream_machine/../.._result.jpg}\")\n",
    "    dialogue_text: str = Field(..., description=\"The dialogue text of a SINGLE character for a particular scene.\")\n",
    "    voice_idx: int = Field(..., description=\"Out of the following voice ids, choose the index of the one that best suits the character who is speaking:\\\n",
    "    [{UgBBYS2sOqTuMpoF3BR0: Male younger and nervous},{N2lVS1w4EtoT3dr4eOWO: Male booming and imposing},\\\n",
    "    {21m00Tcm4TlvDq8ikWAM: Female elegant and slightly teasing},{UgBBYS2sOqTuMpoF3BR0: Male, middle-aged, natural, casual and smooth},\\\n",
    "    {19STyYD15bswVz51nqLf: Female, trustworhy, warm, middle-aged},{gOkFV1JMCt0G0n9xmBwV: Male, middle-older, controlled, honest, respected}]\")\n",
    "audioIdx = 0\n",
    "generatingDialogueAudio = False\n",
    "@tool(\"dialogue_gen_tool\",args_schema=dialogue_gen_schema)\n",
    "def generate_dialogue(character_name: str,character_profile: str,dialogue_text: str, voice_idx: int) -> str:\n",
    "    global chronological_dialogue_duration\n",
    "    global chronological_dialogue_mp3_path\n",
    "    global chrono_character\n",
    "    global character_profiles_chrono\n",
    "    global dialogueQueue\n",
    "    global audioIdx\n",
    "    global generatingDialogueAudio\n",
    "    print(\"attempted dialogue: \" +dialogue_text+\"\\nattempted idx: \" + str(voice_idx))\n",
    "    if(dialogueQueue<=0):\n",
    "        return \"Already generated all dialogue!\"\n",
    "    while(generatingDialogueAudio):\n",
    "        time.sleep(5)\n",
    "        print(\"waiting for dialogue gen process to finish first\")\n",
    "    generatingDialogueAudio = True\n",
    "    voice_ids = [\"29vD33N1CtxCmqQRPOHJ\",\"N2lVS1w4EtoT3dr4eOWO\",\"21m00Tcm4TlvDq8ikWAM\",\"UgBBYS2sOqTuMpoF3BR0\",\"19STyYD15bswVz51nqLf\",\"gOkFV1JMCt0G0n9xmBwV\"]\n",
    "    eleven_response = elevenlabs_client.text_to_speech.convert(\n",
    "        voice_id=voice_ids[voice_idx],\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_44100_128\",\n",
    "        text=dialogue_text,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "    )\n",
    "    \n",
    "    # Save the file into the raw_audio directory\n",
    "    raw_audio_dir = \"staticAudio1\"\n",
    "    os.makedirs(raw_audio_dir, exist_ok=True)\n",
    "    file_path = os.path.join(raw_audio_dir, f\"{audioIdx}.mp3\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        for chunk in eleven_response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    duration = 0\n",
    "    try:\n",
    "        probe = ffmpeg.probe(file_path)\n",
    "        duration = float(probe['format']['duration'])\n",
    "        chronological_dialogue_mp3_path.append(file_path)\n",
    "        chronological_dialogue_duration.append(duration)\n",
    "        chrono_character.append(character_name)\n",
    "        character_profiles_chrono.append(character_profile)\n",
    "        print(\"duration: \" + str(duration) + \"\\ncharacterSpeaking: \" + character_name +\"\\ncharProfile: \" + character_profile)\n",
    "        dialogueQueue-=1\n",
    "        audioIdx+=1\n",
    "        generatingDialogueAudio = False\n",
    "        return file_path\n",
    "    except ffmpeg.Error as e:\n",
    "        generatingDialogueAudio = False\n",
    "        print(\"Error probing file:\", e.stderr)\n",
    "        raise e\n",
    "    \n",
    "audio_tools = [generate_dialogue]\n",
    "audio_tool_node = ToolNode(audio_tools)\n",
    "audio_worker = audio_gen_llm.bind_tools(audio_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a750a2f-6132-407a-b409-57ce8329ca93",
   "metadata": {},
   "source": [
    "### Editor Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1ab92a-8143-4bbe-86e4-a6c4f35a4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class combine_video_dialogue_schema(BaseModel):\n",
    "    \"\"\"Combines a mp3 and mp4 into one video and cuts it accordingly and then returns the filepath to the edited file\"\"\"\n",
    "    video_index: int= Field(..., description=\"The index of the audio and video files to attempt to combine MUST be less than the number of distinct dialogue lines\")\n",
    "\n",
    "@tool(\"combine_video_dialogue_tool\",args_schema=combine_video_dialogue_schema)\n",
    "def combine_video_dialogue(video_index: int)->str:\n",
    "    global chronological_dialogue_duration\n",
    "    print(\"Combining vid and dialogue\")\n",
    "    if(video_index>=len(chronological_dialogue_duration)):\n",
    "        return f\"This index is out of bounds, there are currently {len(chronological_dialogue_duration)} elements in this array\"\n",
    "    try:\n",
    "        # Create inputs for video and audio.\n",
    "        # Using the '.video' and '.audio' attributes helps ensure we use the correct streams.\n",
    "        video_input = ffmpeg.input(f\"staticVid1/{video_index}.mp4\").video\n",
    "        audio_input = ffmpeg.input(f\"staticAudio1/{video_index}.mp3\").audio\n",
    "\n",
    "        # Build the output stream:\n",
    "        # - 'vcodec=\"copy\"' copies the video stream without re-encoding.\n",
    "        # - 'acodec=\"aac\"' encodes the audio to AAC for MP4 compatibility.\n",
    "        # - 't=mp3_duration' instructs FFmpeg to limit the output duration to the provided value.\n",
    "        out = (\n",
    "            ffmpeg\n",
    "            .output(video_input, audio_input, f\"staticAudioVid/{video_index}.mp4\",\n",
    "                    vcodec='copy', acodec='aac', t=chronological_dialogue_duration[video_index])\n",
    "            .overwrite_output()  # Overwrite output file if it exists.\n",
    "        )\n",
    "\n",
    "        # Run the FFmpeg command.\n",
    "        ffmpeg.run(out)\n",
    "        print(f\"Successfully created staticAudioVid/{currentVidIdx}.mp4\")\n",
    "        return f\"staticAudioVid/{currentVidIdx}.mp4\";\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        # If an error occurs, decode and print the stderr.\n",
    "        error_message = e.stderr.decode('utf-8') if e.stderr else str(e)\n",
    "        print(\"An error occurred while combining audio and video:\")\n",
    "        print(error_message)\n",
    "\n",
    "editor_tools = [combine_video_dialogue]\n",
    "editor_tool_node = ToolNode(editor_tools)\n",
    "editor_worker = editor_llm.bind_tools(editor_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76812a2d-d0f4-4679-91e2-ed9e49ede09d",
   "metadata": {},
   "source": [
    "## RUNNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbeb42-ff84-4b08-89ac-e84f2471fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor\n",
      "traveling\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "storyboarding\n",
      "STORY ANALYSIS\n",
      "------------------------------\n",
      "In the Montague Museum, a former family home now turned into a touristic attraction resembling the grandeur of Hearst Castle, a tense confrontation unfolds between Elizabeth Montague and Ethan. Elizabeth, embodying a powerful mix of intensity and anger, tries to discuss a sensitive topic with Ethan, attempting to keep a secret undisclosed. However, Ethan, driven by a sense of duty or perhaps rebellious defiance, resolutely opposes her, expressing his intention to reveal what he knows. This confrontation occurs in an area filled with artifacts and reminders of the once opulent Montague lifestyle, providing a dramatic backdrop to their heated exchange.\n",
      "CHARACTERS\n",
      "------------------------------\n",
      "Elizabeth Montague is fiercely independent, strong-willed, and deeply protective of her family's legacy. Her passion often translates into a fiery disposition, especially when the status or secrets of the Montague lineage are threatened. She is meticulous about controlling information concerning her family's history and resents any hint of betrayal. Her emotions during the conversation with Ethan are raw and powerful, as she struggles to maintain control over the situation.\n",
      "\n",
      "Ethan is in his mid-30s, possessing an energetic demeanor that often comes off as brash or rebellious. He is someone who dislikes secrecy and believes in transparency, which places him at odds with Elizabeth's secretive nature. Motivated by what he considers to be a greater good, Ethan is not afraid to challenge authority and confront situations head-on, even if this results in conflicts with individuals like Elizabeth who represent the 'old guard.' His interactions are often fiery and impassioned, driven by a relentless pursuit of honesty.\n",
      "BACKGROUND\n",
      "------------------------------\n",
      "The scene is set within the Montague Museum, encapsulating both the elegance and the faded glory of the once-grand family estate. Antique furnishings, elegant yet slightly worn carpets, and grand tapestries adorn the environment, narrating tales of past opulence. Hallways echo with soft footsteps, a testament to both the large, empty spaces and the sparse yet noticeable presence of visitors.\n",
      "AUDIO\n",
      "------------------------------\n",
      "Elizabeth's voice is sharp and commanding, with each word driven by her underlying anger and urgency. She frequently emphasizes certain words, cutting through the air with clarity. Ethan's voice, contrasting Elizabeth's, is firm but more relaxed, carrying an edge of defiance and sarcasm. He enunciates his points with a tone that suggests both a desire to provoke and a steadfast belief in his own viewpoint.\n",
      "DIALOGUE\n",
      "------------------------------\n",
      "Elizabeth's dialogue requires enunciation on words that express secrecy and control, such as \"soul\" and \"can't.\" Her anger should be palpable, with voice rising slightly as tension in the conversation builds. Ethan's lines focus on defiance, with emphasis needed on the intention-laden word \"everyone,\" signaling his openness and rebellion. His tone should reveal both his firm resolve and underlying challenge to Elizabeth's demands.\n",
      "Number of characters\n",
      "------------------------------\n",
      "2\n",
      "Pure Dialogue\n",
      "------------------------------\n",
      "Elizabeth: You know you can’t tell a soul, right? (Intense) Ethan: Are you kidding? I’m going to tell everyone. (Defiant) You can’t hide this.\n",
      "Unique Dialogue Instances\n",
      "------------------------------\n",
      "2\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "generating char profile for: Elizabeth Montague\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "paused char profile gen, waiting for first generation to complete\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "paused char profile gen, waiting for first generation to complete\n",
      "Dreaming, state:completed\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/2639271d-a456-485d-91b0-2555fa7659ae/eaef998c-c00f-4c85-861c-0ad952866905_result.jpg\n",
      "Image generated in charRef/0.jpg\n",
      "paused char profile gen, waiting for first generation to complete\n",
      "generating char profile for: Ethan\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:queued\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:completed\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/d81e4430-9594-46f3-a48f-636290280019/597105b0-68ff-451b-9132-9ea0ce65e199_result.jpg\n",
      "Image generated in charRef/1.jpg\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "supervisor\n",
      "traveling\n",
      "audio worker\n",
      "check audio tool call\n",
      "attempted dialogue: You know you can't tell a soul, right?\n",
      "attempted idx: 4\n",
      "attempted dialogue: Are you kidding? I'm going to tell everyone. You can't hide this.\n",
      "attempted idx: 0\n",
      "duration: 2.50775\n",
      "characterSpeaking: Elizabeth\n",
      "charProfile: https://storage.cdn-luma.com/dream_machine/2639271d-a456-485d-91b0-2555fa7659ae/eaef998c-c00f-4c85-861c-0ad952866905_result.jpg\n",
      "waiting for dialogue gen process to finish first\n",
      "duration: 4.310188\n",
      "characterSpeaking: Ethan\n",
      "charProfile: https://storage.cdn-luma.com/dream_machine/d81e4430-9594-46f3-a48f-636290280019/597105b0-68ff-451b-9132-9ea0ce65e199_result.jpg\n",
      "audio worker\n",
      "check audio tool call\n",
      "supervisor\n",
      "traveling\n",
      "video worker\n",
      "check video tool call\n",
      "START KEYFRAME PROMPT: The scene opens inside the Montague Museum, where the grandeur of past eras is palpable. As the camera pans across the elegantly aged furnishings and antiquated tapestries, it captures the essence of a once opulent family residence now transformed into a public museum. Amidst this setting, Elizabeth Montague stands with a fierce expression, her posture and eyes reflecting both authority and urgency. Around her, the ambient lighting highlights her stern yet determined demeanor as she begins an intensely emotional conversation. Her presence and the presence of the historic artifacts around her set a powerful visual tone for the unfolding confrontation.\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:completed\n",
      "start_keyframe_image_url: https://storage.cdn-luma.com/dream_machine/bd644961-d53a-4d54-9f73-48ff9e1727d3/fc834bf8-9b1b-4527-9325-a5c01ea05f39_result.jpg\n",
      "Image generated in staticStartKeyFrame/0.jpg\n",
      "END KEYFRAME PROMPT: The intensity of the moment deepens as Elizabeth, her fiery expression unwavering, concludes her plea with Ethan. Her strong features are captured in the quiet aftermath of her declaration, underscoring the gravity of her warning. The background shifts slightly as Ethan's resolute figure comes into focus, signifying the brewing conflict. The dimly lit surroundings of the Montague Museum amplify the tension in the atmosphere, mirrored in Elizabeth's unwavering gaze as she awaits Ethan's reaction.\n",
      "End Keyframe Dreaming, state:queued\n",
      "End Keyframe Dreaming, state:queued\n",
      "End Keyframe Dreaming, state:queued\n",
      "End Keyframe Dreaming, state:queued\n",
      "End Keyframe Dreaming, state:queued\n",
      "End Keyframe Dreaming, state:dreaming\n",
      "End Keyframe Dreaming, state:dreaming\n",
      "End Keyframe Dreaming, state:dreaming\n",
      "End Keyframe Dreaming, state:dreaming\n",
      "End Keyframe Dreaming, state:completed\n",
      "end_keyframe_image_url: https://storage.cdn-luma.com/dream_machine/58eff02a-21f5-4e79-b5d4-af0a62fba043/53e733a4-6f8c-439b-89ed-9fb70a820932_result.jpg\n",
      "Image generated in staticEndKeyFrame/0.jpg\n",
      "VIDEOWORKER PROMPT: 9s\n",
      "------------------------------\n",
      "Elizabeth Montague stands heavily in focus as she speaks, her intense demeanor dominating the frame. Her words are accompanied by subtle shifts in her brow and lips, an interplay of frustration and caution etched onto her features. The historical artifacts surrounding her serve as silent witnesses, their presence amplifying Elizabeth's commanding presence and emotional gravitas.\n",
      "generating vid\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "Dreaming, state:dreaming\n",
      "FAILED VID\n",
      "video worker\n",
      "check video tool call\n",
      "START KEYFRAME PROMPT: Elizabeth Montague starts the scene amidst the elegant antiquities and tapestries of the Montague Museum, exuding a palpable intensity. Her sharp features and commanding presence are accentuated by the museum's subdued lighting, reflecting her urgent and formidable demeanor. The backdrop of opulent yet faded grandeur underscores her determination as she prepares to confront Ethan. There is a sense of drama as the camera zooms in to capture her poised stance, conveying her blend of authority and emotion about to be directed at Ethan.\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:queued\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:dreaming\n",
      "Start Keyframe Dreaming, state:completed\n",
      "start_keyframe_image_url: https://storage.cdn-luma.com/dream_machine/3453a691-1f44-4622-96b2-1c96b8f86a57/a10a0001-b09c-498f-a294-7647425283aa_result.jpg\n",
      "Image generated in staticStartKeyFrame/0.jpg\n",
      "END KEYFRAME PROMPT: As the confrontation between Elizabeth and Ethan intensifies, Elizabeth’s disdain is vividly captured in her formidable expression. Her steely gaze rests on Ethan, maintaining a firm stance that conveys both strength and unease. The artful angle captures the intricate architectural elements of the museum as her figure gradually becomes part of this historical mosaic. This ending scene signifies Elizabeth's determination to uphold her family's legacy amidst the underlying dispute.\n",
      "End Keyframe Dreaming, state:queued\n"
     ]
    }
   ],
   "source": [
    "members = [\"video_worker\",\"storyboard_worker\",\"audio_worker\",\"editor_worker\"] #\"editor\"\n",
    "supervisor_options = members + [END]\n",
    "visitedAudioWorker = False\n",
    "class Supervisor_Router(TypedDict):\n",
    "    \"\"\"Worker to route to next to fulfill the user's request. If no workers are needed, route to END.\"\"\"\n",
    "\n",
    "    next: Literal[*supervisor_options]\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def go_next(state: MessagesState) -> Literal[*supervisor_options]:\n",
    "    global visitedAudioWorker\n",
    "    print(f\"traveling\")\n",
    "    if(state[\"next\"]==\"video_worker\" and not visitedAudioWorker):\n",
    "        print(\"forced audio travel\")\n",
    "        visitedAudioWorker = True\n",
    "        return \"audio_worker\"\n",
    "    return state[\"next\"]\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_supervisor(state: MessagesState):\n",
    "    print(\"supervisor\")\n",
    "    messages = state[\"messages\"]\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a supervisor of a short film project and am in charge of a team of 4. You can delegate relevant tasks to any of these members: {members}.\"\n",
    "        \"Bob the video_worker is capable of generating high fidelity videos, but requires clear contextual information. Ryan the audio_worker is able to generate character\"\n",
    "        \"dialogue audio clips. Steve the storyboard_worker is able to analyze a given input script and break it down into fine details and generate character profiles.\"\n",
    "        \"\\nYou should ALWAYS ensure Steve has generated a STORYBOARD and character profiles for ALL characters analyzed in the storyboard tool response before anything else.\"\n",
    "        \"\\nIMPORTANT!!! MAKE SURE Ryan generates audio clips BEFORE Bob generates video clips. Generate a step-by-step plan from the following prompt and act on it.\"\n",
    "        \"\\nEXAMPLE PLAN(FOLLOW): STEVE STORYBOARD -> STEVE CHARACTER PROFILES -> RYAN AUDIO CLIPS -> BOB VIDEO GENERATION -> DAVE EDITOR\"\n",
    "        \"When responding, please output a JSON object that follows this schema:\\n\"\n",
    "        '{ \"next\": one of the allowed values: ' + \", \".join(supervisor_options) + \" }\\n\"\n",
    "        \"If no further workers are needed, output 'END' as the next step.\"\n",
    "    }\n",
    "    response = supervisor_llm.with_structured_output(Supervisor_Router).invoke(messages)\n",
    "    # Wrap the response in a valid message format\n",
    "    structured_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Routing to {response['next']}\"\n",
    "    }\n",
    "    return {\"messages\": [structured_message], \"next\": response[\"next\"]}\n",
    "\n",
    "def call_video_worker(state: MessagesState):\n",
    "    global chrono_character\n",
    "    global chronological_dialogue_duration\n",
    "    global currentDialogueIdx\n",
    "    print(\"video worker\")\n",
    "    messages = state['messages']\n",
    "    extraStr = \"video being generated before generating another. [Use Unique Prompts].\"\n",
    "    if(currentDialogueIdx<len(chrono_character)):\n",
    "        extraStr = f\"video being generated before generating another. [Use Unique Prompts]. YOU ARE CURRENTLY GEENRATING A {chronological_dialogue_duration[currentDialogueIdx]} DIALOGUE VIDEO FOR: {chrono_character[currentDialogueIdx]} ENSURE START AND END KEYFRAME ALONG WITH VIDEO PROMPT ARE ABOUT THIS CHARACTER\"\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Bob, a video worker. Process the given request accordingly. Note that you can only generate 5 second or 9 second videos.\"\n",
    "        \"CONTINUE generating videos until you no longer can. Generate only ONE video at a time. Wait until you have received the filepath of the current\" + extraStr\n",
    "    }\n",
    "    response = video_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_storyboard_worker(state: MessagesState):\n",
    "    print(\"storyboard worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are Steve, a storyboarder. Process the given request accordingly. You have access to two tools: a storyboard generator and a character profile\\\n",
    "        generator. Generate only ONE character profile at a time. You should pass in all character results from the storyboard generator into the character profile generator.\"\n",
    "    }\n",
    "    response = storyboard_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_audio_worker(state: MessagesState):\n",
    "    global visitedAudioWorker\n",
    "    global fullDialogueString\n",
    "    print(\"audio worker\")\n",
    "    visitedAudioWorker=True\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Ryan, a character dialogue generator. Process the given request accordingly. You have access to one tool\"\n",
    "        \"which generates a dialogue audio clip for a SINGLE character talking ONLY AS PER THE CHRONOLOGICAL OREDER of the storyboard generated by STEVE.\"\n",
    "        \"Check if you have already generated a piece of dialogue. If you have, don't generate it again.\"\n",
    "        \"Parse this string once for each instance with a character talking generate audio:\"+ fullDialogueString\n",
    "    }\n",
    "    response = audio_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "    \n",
    "def call_editor_worker(state: MessagesState):\n",
    "    print(\"editor worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are Dave, a video editor. Process the given request accordingly. You have access to one tool that allows you to combine an mp3 and mp4 file and cut the length\\\n",
    "        so that the video will end when the audio ends. CONTINUE combining until you run out of indices to plug into the tool. REMEMBER that the max index is the number of distinct dialogue instances minus 1\"\n",
    "    }\n",
    "    response = editor_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def check_video_tool_calls(state: MessagesState) -> Literal[\"video_tools\",\"supervisor\"]:\n",
    "    print(\"check video tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"video_tools\"\n",
    "    print(\"doesn't want to use tool\")\n",
    "    return \"supervisor\"\n",
    "\n",
    "def check_storyboard_tool_calls(state: MessagesState) -> Literal[\"storyboard_tools\",\"supervisor\"]:\n",
    "    print(\"check storyboard tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"storyboard_tools\"\n",
    "    return \"supervisor\"\n",
    "    \n",
    "def check_audio_tool_calls(state: MessagesState) -> Literal[\"audio_tools\",\"supervisor\"]:\n",
    "    print(\"check audio tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"audio_tools\"\n",
    "    return \"supervisor\"\n",
    "\n",
    "def check_editor_tool_calls(state: MessagesState) -> Literal[\"editor_tools\",\"supervisor\"]:\n",
    "    print(\"check editor tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"editor_tools\"\n",
    "    return \"supervisor\"\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"supervisor\", call_supervisor)\n",
    "workflow.add_node(\"video_worker\", call_video_worker)\n",
    "workflow.add_node(\"video_tools\", video_tool_node)\n",
    "workflow.add_node(\"storyboard_worker\", call_storyboard_worker)\n",
    "workflow.add_node(\"storyboard_tools\", storyboard_tool_node)\n",
    "workflow.add_node(\"audio_worker\", call_audio_worker)\n",
    "workflow.add_node(\"audio_tools\", audio_tool_node)\n",
    "workflow.add_node(\"editor_worker\", call_editor_worker)\n",
    "workflow.add_node(\"editor_tools\", editor_tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    go_next,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"video_worker\",\n",
    "    check_video_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"storyboard_worker\",\n",
    "    check_storyboard_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"audio_worker\",\n",
    "    check_audio_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"editor_worker\",\n",
    "    check_editor_tool_calls,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"video_tools\", 'video_worker')\n",
    "workflow.add_edge(\"storyboard_tools\",\"storyboard_worker\");\n",
    "workflow.add_edge(\"audio_tools\",\"audio_worker\");\n",
    "workflow.add_edge(\"editor_tools\",\"editor_worker\");\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "generatingImg = False\n",
    "generatingVid = False\n",
    "# Use the agent\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Generate a STORYBOARD, AUDIO, AND VIDEO FOR ALL CHARACTERS THEN EDIT THE VIDEO AND AUDIO FILES TOGETHER for the following scene: INT. MONTAGUE MUSEUM – MODERN DAYThe once-grand family home, now a tour-driven Hearst Castle-like museum.ELIZABETH MONTAGUE, intense and angry, argues with Ethan.ELIZABETHYou know you can’t tell a soul,right?ETHANAre you kidding? I’m going to telleveryone. You can’t hide this.\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361d425-25ad-4987-b386-312e4a09d0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
