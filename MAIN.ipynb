{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a0b91f-1ab1-423d-890d-3c0f4e3c6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir('Lib/site-packages')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "import ffmpeg\n",
    "import json\n",
    "import time\n",
    "#import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from lumaai import LumaAI\n",
    "from typing import Literal, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7c9450-b7f9-49e2-846a-03b8bead1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUMA\n",
    "client = LumaAI(\n",
    "    auth_token=os.environ.get(\"LUMAAI_API_KEY\"),\n",
    ")\n",
    "#OPENAI\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "#LANGCHAIN llms\n",
    "supervisor_llm = init_chat_model(\"o1\", model_provider=\"openai\")\n",
    "video_gen_llm = init_chat_model(\"o1-mini\", model_provider=\"openai\")\n",
    "storyboard_llm = init_chat_model(\"o1-mini\", model_provider=\"openai\")\n",
    "#audio_gen_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "#editor_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "generatingVid = False\n",
    "generatingImg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dc3f3-a4e8-4fd0-9ffc-b7244c81da71",
   "metadata": {},
   "source": [
    "## TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bd710-06c9-432d-9602-c38a3f7a5fba",
   "metadata": {},
   "source": [
    "### Video Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9958d677-52aa-48e2-a95b-5e2278d3254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMAS\n",
    "class video_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a video using text input and returns a filepath to the video\"\"\"\n",
    "    vid_prompt: str = Field(..., description=\"The textual prompt used in generating the video\")\n",
    "    use_9s: bool = Field(..., description=\"Whether to generate a 9 second long video. If set to FALSE, this will generate a 5 second long video\")\n",
    "\n",
    "\n",
    "@tool(\"video_gen_tool\",args_schema=video_gen_schema)   \n",
    "def generate_vid(vid_prompt: str, use_9s: bool) -> str:\n",
    "    global generatingVid\n",
    "    if(generatingVid):\n",
    "        return \"Failed to generate video, there is currently another video being generated.\"\n",
    "    dur = \"5s\"\n",
    "    if(use_9s):\n",
    "        dur = \"9s\"\n",
    "    print(f\"VIDEOWORKER PROMPT: {dur}\\n------------------------------\\n\" + vid_prompt)\n",
    "    generatingVid = True\n",
    "    generation = client.generations.create(\n",
    "        prompt=vid_prompt,\n",
    "        model=\"ray-2\",\n",
    "        resolution=\"720p\",\n",
    "        duration=dur\n",
    "    )\n",
    "    completed = False\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming\")\n",
    "      time.sleep(5)\n",
    "    video_url = generation.assets.video\n",
    "    # download the video\n",
    "    response = requests.get(video_url, stream=True)\n",
    "    with open(f'staticVid1/{generation.id}.mp4', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Video generated in staticVid1/{generation.id}.mp4\")\n",
    "    generatingVid = False\n",
    "    return f\"Video generated in staticVid1/{generation.id}.mp4\"\n",
    "\n",
    "#class extend_video_schema(BaseModel):\n",
    "video_tools = [generate_vid]\n",
    "video_tool_node = ToolNode(video_tools)\n",
    "video_worker = video_gen_llm.bind_tools(video_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5b6e-939f-4b35-b636-9e8842e04e44",
   "metadata": {},
   "source": [
    "### Storyboard Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91838bf-2756-46e3-955b-8689016710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCHEMA\n",
    "class step_by_step_output_schema(BaseModel):\n",
    "    \"\"\"Prints a storyboard for the user to view in string format\"\"\"\n",
    "    story_description: str = Field(..., description=\"A 200-250 word description of the story\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of each character in the scene\")\n",
    "    background_details: str = Field(..., description=\"A 50-100 description of the scene\")\n",
    "    auditory_details: str = Field(..., description=\"A 50-100 description of the voice profile of each character\")\n",
    "    dialogue_details: str = Field(..., description=\"The parts of the dialogue that require enunciation and emotion\")\n",
    "\n",
    "@tool(\"storyboard_tool\",args_schema=step_by_step_output_schema)\n",
    "def generate_storyboard(story_description: str,character_details: str,background_details: str,auditory_details: str,dialogue_details: str) -> str:\n",
    "    temp_storyboard = \"STORY ANALYSIS\\n------------------------------\\n\"+story_description+\"\\nCHARACTERS\\n------------------------------\\n\"+character_details\n",
    "    temp_storyboard+=\"\\nBACKGROUND\\n------------------------------\\n\"+background_details+\"\\nAUDIO\\n------------------------------\\n\"+auditory_details+\"\\nDIALOGUE\\n------------------------------\\n\"+dialogue_details\n",
    "    print(temp_storyboard)\n",
    "    return temp_storyboard\n",
    "\n",
    "class character_profile_gen_schema(BaseModel):\n",
    "    \"\"\"Generates a character profile for a character and returns the filepath\"\"\"\n",
    "    character_name: str = Field(..., description=\"The name of the character, taken from the script\")\n",
    "    character_details: str = Field(..., description=\"A 200-300 word description of the character in the scene, taken from the script\")\n",
    "\n",
    "@tool(\"character_profile_tool\",args_schema=character_profile_gen_schema)\n",
    "def generate_character_profile(character_name: str, character_details: str)->str:\n",
    "    global generatingImg\n",
    "    if(generatingImg):\n",
    "        return \"Failed to generate image, there is currently another image being generated\"\n",
    "    generatingImg = True\n",
    "    generation = client.generations.image.create(\n",
    "      prompt=\"Generate a hyperrealistic, front-facing portrait \\\n",
    "      The image should feature perfectly even, diffused lighting that completely\\\n",
    "      eliminates any shadows on the face. Use a direct, center-camera angle against a neutral,\\\n",
    "      unobtrusive background to ensure absolute consistency. Focus on lifelike details with natural \\\n",
    "      skin textures and realistic, balanced color tones, making the portrait suitable as a reference\\\n",
    "      for video character consistency.: \"+character_name+\", \"+character_details,\n",
    "    )\n",
    "    completed = False\n",
    "    while not completed:\n",
    "      generation = client.generations.get(id=generation.id)\n",
    "      if generation.state == \"completed\":\n",
    "        completed = True\n",
    "      elif generation.state == \"failed\":\n",
    "        raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "      print(\"Dreaming\")\n",
    "      time.sleep(2)\n",
    "    image_url = generation.assets.image\n",
    "    print(\"image_url: \" +image_url)\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    with open(f'charRef/{generation.id}.jpg', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Image generated in charRef/{generation.id}.jpg\")\n",
    "    generatingImg = False\n",
    "    return f\"Image generated in charRef/{generation.id}.jpg\"\n",
    "\n",
    "storyboard_tools = [generate_storyboard,generate_character_profile]\n",
    "storyboard_tool_node = ToolNode(storyboard_tools)\n",
    "storyboard_worker = storyboard_llm.bind_tools(storyboard_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf12443-0259-452e-bf07-27d0d57f9593",
   "metadata": {},
   "source": [
    "### Audio Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd454937-f86f-4a39-84fa-e8671ce437be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a750a2f-6132-407a-b409-57ce8329ca93",
   "metadata": {},
   "source": [
    "### Editor Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9813c-89d5-4494-8240-ada2fb717f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc4a56e5-9e4a-4295-a3ad-701fe0d94998",
   "metadata": {},
   "source": [
    "### Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285569a5-9089-4d81-9773-2eaf1ab11dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76812a2d-d0f4-4679-91e2-ed9e49ede09d",
   "metadata": {},
   "source": [
    "## RUNNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcbeb42-ff84-4b08-89ac-e84f2471fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor\n",
      "traveling\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "STORY ANALYSIS\n",
      "------------------------------\n",
      "In the grand yet faded Montague Museum, a once opulent family home turned tourist attraction, an argument brews between two key figures, Elizabeth and Ethan. The air is thick with tension as Elizabeth, an embodiment of noble rage, stands fiercely with her arms akimbo. Ethan, the rebellious younger counterpart, leans slightly against a marble pillar, the very picture of defiance. Their voices rise and fall amidst the echoes of the museum, a stark contrast to the whispers of history that surround them. Elizabeth, fiercely protective of her family's legacy, is determined to keep a secret buried, while Ethan, a wildcard, sees the value in exposing the truth. The stark lighting and grand museum backdrop offer a stunning contrast to their intimate confrontation, lending a dramatic flair to the unfolding familial conflict. As the argument escalates, the camera captures close-ups of their faces, highlighting their emotional turmoil and the stakes at hand. Elizabeth’s eyes burn with intensity while Ethan smirks with disbelief, underscoring their differing values and motivations. The scene promises a clash of ideals, family loyalty versus personal freedom, all set within the echoing halls of history and legacy.\n",
      "CHARACTERS\n",
      "------------------------------\n",
      "ELIZABETH MONTAGUE: A fierce and intense woman in her late 30s, Elizabeth exudes a palpable frustration and anger, driven by her need to protect her family's reputation. Her attire is formal yet stylish, hinting at her family's former glory. She has piercing blue eyes and dark hair pulled back tightly, suggesting her tightly wound disposition. There is a tension in her posture as she stands her ground against Ethan. \n",
      "\n",
      "ETHAN: A rebellious and confident young man in his early 20s, Ethan showcases a carefree spirit that clashes with Elizabeth’s heavy intensity. His casual attire contrasts with Elizabeth's formal appearance, symbolizing his carefree attitude towards their family's legacy. With tousled hair and an expressive face, he embodies defiance, ready to challenge the expectations thrust upon him. His body language is relaxed yet assertive, emphasizing his eagerness to unveil the secrets of their past.\n",
      "BACKGROUND\n",
      "------------------------------\n",
      "The setting is the Montague Museum, once the prestigious family home of the Montagues, transformed now into a museum reminiscent of the Hearst Castle. The walls are adorned with historical artifacts, and the elegant architecture showcases the remnants of a bygone era. Tall, arched windows allow beams of light to filter in, illuminating dust particles in the air, making the space almost ethereal. Antique furniture and portraits of ancestors create a haunting backdrop for the confrontation, evoking a sense of family history lingering in the air. The museum's grandeur juxtaposes the intimate conflict taking place between Elizabeth and Ethan.\n",
      "AUDIO\n",
      "------------------------------\n",
      "ELIZABETH has a commanding and sharp voice, filled with intensity and urgency, her words hanging heavily in the air. Her tone conveys both anger and desperation, emphasizing her urgency to protect their family’s secret. \n",
      "\n",
      "ETHAN speaks with a casual, carefree tone, punctuated by a hint of amusement and defiance. His words are laced with sarcasm, showcasing his rebellious nature and lack of regard for the family legacy Elizabeth clings to.\n",
      "DIALOGUE\n",
      "------------------------------\n",
      "ELIZABETH: (intense, enunciating every word) You know you can’t tell a soul, right? \n",
      "\n",
      "ETHAN: (sarcastic, mocking) Are you kidding? I’m going to tell everyone. You can’t hide this.\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "image_url: https://storage.cdn-luma.com/dream_machine/25dda232-01c2-400f-92f8-4af339cb6874/0dea0c32-b06a-4f57-a148-1752e1200371_result.jpg\n",
      "Image generated in charRef/d741d62e-9405-43b0-a629-8c0278655be9.jpg\n",
      "storyboard worker\n",
      "check storyboard tool call\n",
      "supervisor\n",
      "traveling\n",
      "video worker\n",
      "check video tool call\n",
      "VIDEOWORKER PROMPT: 9s\n",
      "------------------------------\n",
      "In the Montague Museum, Elizabeth Montague, a fierce woman in her late 30s, confronts Ethan, a rebellious young man in his early 20s. The scene captures the grandeur of the once-opulent museum while the two engage in a heated argument. Elizabeth stands intensely with arms crossed, urging Ethan not to share a secret. Ethan smirks back defiantly, teasing that he will tell everyone. Their contrasting appearances and attitudes highlight a clash between familial loyalty and personal freedom. The echoes of history surround them, amplifying the tension of their exchange.\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Dreaming\n",
      "Video generated in staticVid1/f5e26039-cad8-429e-8446-15d3884e62ba.mp4\n",
      "video worker\n",
      "check video tool call\n",
      "supervisor\n",
      "traveling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Routing to __end__'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = [\"video_worker\",\"storyboard_worker\"] #\"audio_worker\",\"editor\"\n",
    "supervisor_options = members + [END]\n",
    "\n",
    "class Supervisor_Router(TypedDict):\n",
    "    \"\"\"Worker to route to next to fulfill the user's request. If no workers are needed, route to END.\"\"\"\n",
    "\n",
    "    next: Literal[*supervisor_options]\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def go_next(state: MessagesState) -> Literal[*supervisor_options]:\n",
    "    print(f\"traveling\")\n",
    "    return state[\"next\"]\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_supervisor(state: MessagesState):\n",
    "    print(\"supervisor\")\n",
    "    messages = state[\"messages\"]\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a supervisor of a short film project and am in charge of a team of 4. You can delegate relevant tasks to any of these members: {members}.\\\n",
    "        Bob the video_worker is capable of generating high fidelity videos, but requires clear contextual information. Steve the storyboard_worker is able to analyze\\\n",
    "        a given input script and break it down into fine details and generate character profiles. You should ALWAYS ensure Steve has generated a STORYBOARD and TWO\\\n",
    "        character profiles before anything else. Generate a step-by-step plan from the following prompt and act on it.\"\n",
    "    }\n",
    "    response = supervisor_llm.with_structured_output(Supervisor_Router).invoke(messages)\n",
    "    # Wrap the response in a valid message format\n",
    "    structured_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Routing to {response['next']}\"\n",
    "    }\n",
    "    return {\"messages\": [structured_message], \"next\": response[\"next\"]}\n",
    "\n",
    "def call_video_worker(state: MessagesState):\n",
    "    print(\"video worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Bob, a video worker. Process the given request accordingly. Note that you can only generate 5 second or 9 second videos.\\\n",
    "        If you need to generate further content, ensure the characters and the scene in the video are consistent by providing similar prompts.\\\n",
    "        Generate only ONE video at a time. Wait until you have received the filepath of the current video being generated before generating another. [Use Unique Prompts]\"\n",
    "    }\n",
    "    response = video_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_storyboard_worker(state: MessagesState):\n",
    "    print(\"storyboard worker\")\n",
    "    messages = state['messages']\n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Steve, a storyboarder. Process the given request accordingly. You have access to two tools: a storyboard generator and a character profile\\\n",
    "        generator. You should pass in all character results from the storyboard generator into the character profile generator.\"\n",
    "    }\n",
    "    response = storyboard_worker.invoke([context_message]+messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def check_video_tool_calls(state: MessagesState) -> Literal[\"video_tools\",\"supervisor\"]:\n",
    "    print(\"check video tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"video_tools\"\n",
    "    return \"supervisor\"\n",
    "\n",
    "def check_storyboard_tool_calls(state: MessagesState) -> Literal[\"storyboard_tools\",\"supervisor\"]:\n",
    "    print(\"check storyboard tool call\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"storyboard_tools\"\n",
    "    return \"supervisor\"\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"supervisor\", call_supervisor)\n",
    "workflow.add_node(\"video_worker\", call_video_worker)\n",
    "workflow.add_node(\"video_tools\", video_tool_node)\n",
    "workflow.add_node(\"storyboard_worker\", call_storyboard_worker)\n",
    "workflow.add_node(\"storyboard_tools\", storyboard_tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    go_next,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"video_worker\",\n",
    "    check_video_tool_calls,\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"storyboard_worker\",\n",
    "    check_storyboard_tool_calls,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"video_tools\", 'video_worker')\n",
    "workflow.add_edge(\"storyboard_tools\",\"storyboard_worker\");\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "generatingImg = False\n",
    "generatingVid = False\n",
    "# Use the agent\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Generate a STORYBOARD and a VIDEO about the following scene: INT. MONTAGUE MUSEUM – MODERN DAYThe once-grand family home, now a tour-driven Hearst Castle-like museum.ELIZABETH MONTAGUE, intense and angry, argues with Ethan.ELIZABETHYou know you can’t tell a soul,right?ETHANAre you kidding? I’m going to telleveryone. You can’t hide this.\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29635ea7-bfbd-41f6-bfcd-a498d6171f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = client.generations.image.create(\n",
    "    prompt=\"sunglasses\",\n",
    "    image_ref=[\n",
    "      {\n",
    "        \"url\": \"https://storage.cdn-luma.com/dream_machine/7e4fe07f-1dfd-4921-bc97-4bcf5adea39a/video_0_thumb.jpg\",\n",
    "        \"weight\": 0.85\n",
    "      }\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
